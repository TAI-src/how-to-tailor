{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to How to tailor \u00b6 Research in optimization tends to focus on how to improve the design or configuration of their methods from a theoretical perspective or motivated by empirical studies of algorithm behavior on either specific individual problems or broader benchmarking problem suites. Our Dagstuhl Seminar takes a different perspective \u2013 we wish to improve the algorithm practitioner, arming them with a recipe book for improving any one of a broad class of optimization methods (black-box methods) on any given problem, particularly focusing on real-world problems. In order to establish such a recipe book, we must look to real-world problems and first understand how they arrive on the desk of an optimization practitioner. The formulation of the problem itself is often (though not always) \u201cmessy\u201d with many crucial details missing (such as what the objective(s) are, what the decision space is, and what the constraints are)! But even when such details are apparently in place, the practitioner must remember they are choices, and it will be well to understand who has made those choices and why. At a second level, one must understand how many times the optimization problem must be solved, with what frequency, on what machines, with what data and simulators, and so on. At another level, the practitioner must understand uncertainty in the problem, how the solution is represented, how it will be used in practice, what current solution methods are used, and how they were arrived at. By considering these and a large host of other factors, the practitioner can then understand how they might go about leveraging all that domain knowledge to tailor an optimization method for that problem to achieve the best possible tuned method. The challenge for us all is to be able to do this for any given problem and to have tailoring strategies that work well for any (or a wide range of) black-box methods. We know that such general tailoring methods exist in broad outline in the advice given in old textbooks [1], but it is a long time since they were updated for modern optimization methods and modern infrastructure, such as our modern methods of benchmarking algorithms. The purpose of this Dagstuhl Seminar is to audit the current experience that exists in the field, pool it, and start to describe that experience in a way that goes beyond anecdote (although anecdotes can be useful) and moves us toward advice or recipes that actually work in practice. To achieve this, we aim to bring together researchers from a diverse range of backgrounds involved in real-world optimization from the customer side, the algorithm design or theoretical side, or practitioners who have already experienced successes and failures in the endeavor of tailoring algorithms to problems. The format of our seminar will be structured so that we hear from the cross-section of experienced and inexperienced practitioners, algorithm designers and customers, right from the start. We will then self-organize to achieve our aim of sharing our pooled experience and shaping it into practical, searchable and up-to-date advice on leveraging domain knowledge. [1] L. Davis, Handbook of genetic algorithms. Chapman & Hall, London, 1991. Example Collection \u00b6 As a first step, we are aiming to collect examples. Please add your examples (see below).","title":"Welcome to How to tailor"},{"location":"#welcome-to-how-to-tailor","text":"Research in optimization tends to focus on how to improve the design or configuration of their methods from a theoretical perspective or motivated by empirical studies of algorithm behavior on either specific individual problems or broader benchmarking problem suites. Our Dagstuhl Seminar takes a different perspective \u2013 we wish to improve the algorithm practitioner, arming them with a recipe book for improving any one of a broad class of optimization methods (black-box methods) on any given problem, particularly focusing on real-world problems. In order to establish such a recipe book, we must look to real-world problems and first understand how they arrive on the desk of an optimization practitioner. The formulation of the problem itself is often (though not always) \u201cmessy\u201d with many crucial details missing (such as what the objective(s) are, what the decision space is, and what the constraints are)! But even when such details are apparently in place, the practitioner must remember they are choices, and it will be well to understand who has made those choices and why. At a second level, one must understand how many times the optimization problem must be solved, with what frequency, on what machines, with what data and simulators, and so on. At another level, the practitioner must understand uncertainty in the problem, how the solution is represented, how it will be used in practice, what current solution methods are used, and how they were arrived at. By considering these and a large host of other factors, the practitioner can then understand how they might go about leveraging all that domain knowledge to tailor an optimization method for that problem to achieve the best possible tuned method. The challenge for us all is to be able to do this for any given problem and to have tailoring strategies that work well for any (or a wide range of) black-box methods. We know that such general tailoring methods exist in broad outline in the advice given in old textbooks [1], but it is a long time since they were updated for modern optimization methods and modern infrastructure, such as our modern methods of benchmarking algorithms. The purpose of this Dagstuhl Seminar is to audit the current experience that exists in the field, pool it, and start to describe that experience in a way that goes beyond anecdote (although anecdotes can be useful) and moves us toward advice or recipes that actually work in practice. To achieve this, we aim to bring together researchers from a diverse range of backgrounds involved in real-world optimization from the customer side, the algorithm design or theoretical side, or practitioners who have already experienced successes and failures in the endeavor of tailoring algorithms to problems. The format of our seminar will be structured so that we hear from the cross-section of experienced and inexperienced practitioners, algorithm designers and customers, right from the start. We will then self-organize to achieve our aim of sharing our pooled experience and shaping it into practical, searchable and up-to-date advice on leveraging domain knowledge. [1] L. Davis, Handbook of genetic algorithms. Chapman & Hall, London, 1991.","title":"Welcome to How to tailor"},{"location":"#example-collection","text":"As a first step, we are aiming to collect examples. Please add your examples (see below).","title":"Example Collection"},{"location":"examples/","text":"Example Index \u00b6 Optimisation for a Fleet of Healthcare Vehicles (Sarah Thomson) Building spatial design (Koen van der Blom) Combined Topology and Fibre-Orientation via Moving Morphable Components and Lamination Parameters (Iv\u00e1n Olarte Rodr\u00edguez, Gokhan Serhat, Mariusz Bujny, Thomas Baeck, Elena Raponi) Antenna control (Laurens Bliek) Deep RL in Ludii (general game playing) (Dennis Soemers) MarioGAN (Vanessa Volz)","title":"Example Index"},{"location":"examples/#example-index","text":"Optimisation for a Fleet of Healthcare Vehicles (Sarah Thomson) Building spatial design (Koen van der Blom) Combined Topology and Fibre-Orientation via Moving Morphable Components and Lamination Parameters (Iv\u00e1n Olarte Rodr\u00edguez, Gokhan Serhat, Mariusz Bujny, Thomas Baeck, Elena Raponi) Antenna control (Laurens Bliek) Deep RL in Ludii (general game playing) (Dennis Soemers) MarioGAN (Vanessa Volz)","title":"Example Index"},{"location":"examples/example_1/","text":"Optimisation for a Fleet of Healthcare Vehicles \u00b6 Problem Description \u00b6 A healthcare provider in a region of Scotland (Argyll and Bute) wanted to reduce their vehicle fleet size while still being able to cater for all trips. They provided 4 months of historical data about where their existing fleet were based and the trips they conducted, including start and end times and geographic location. We were also given information about the vehicle types and which vehicles were allowed to do which trips. Why was tailoring needed? \u00b6 Not too much tailoring was needed but there were some particulars that had to be accounted for: Jobs (i.e. trips) have a type of vehicle which (historically) executed them, but if needed certain other types of vehicles can do the trip. For example, a small car originally did the trip, can be done by a van. Vehicles can be swapped between geographical bases if needed and if the swap does not mean that the vehicle home base cannot cover its own trips. It does not make sense to try and remove a type of vehicle from a base if there are none there or maybe if there are a small amount there. This led to a semi-guided mutation design. Baseline algorithm \u00b6 Upper level: stochastic local search; lower level: constructive heuristic. Motivations for choice: we wanted to keep it simple as possible and explainable for the user. No need to use fancy algorithms if a simple approach can obtain results. Tailoring process \u00b6 Adding in constraints (part of the operators); added additional vehicle/machine swap operation; semi-guided mutation. What was tailored \u00b6 Aspects of the algorithmic operators were tailored. This included the nature of the mutation operator and how it ensured that mutated solutions are feasible within the specific constraints of the problem. Main problem characteristics \u00b6 Choose most important ones: low-dimensional at upper level, high-dimensional at lower level; highly constrained (some soft and some hard); offline; there is an existing solution that works(current fleet); is a simplified version of what is eventually sought (optimising routes, carbon as well); low data sensitivity. References \u00b6 No response Author \u00b6 Sarah Thomson","title":"Optimisation for a Fleet of Healthcare Vehicles"},{"location":"examples/example_1/#optimisation-for-a-fleet-of-healthcare-vehicles","text":"","title":"Optimisation for a Fleet of Healthcare Vehicles"},{"location":"examples/example_1/#problem-description","text":"A healthcare provider in a region of Scotland (Argyll and Bute) wanted to reduce their vehicle fleet size while still being able to cater for all trips. They provided 4 months of historical data about where their existing fleet were based and the trips they conducted, including start and end times and geographic location. We were also given information about the vehicle types and which vehicles were allowed to do which trips.","title":"Problem Description"},{"location":"examples/example_1/#why-was-tailoring-needed","text":"Not too much tailoring was needed but there were some particulars that had to be accounted for: Jobs (i.e. trips) have a type of vehicle which (historically) executed them, but if needed certain other types of vehicles can do the trip. For example, a small car originally did the trip, can be done by a van. Vehicles can be swapped between geographical bases if needed and if the swap does not mean that the vehicle home base cannot cover its own trips. It does not make sense to try and remove a type of vehicle from a base if there are none there or maybe if there are a small amount there. This led to a semi-guided mutation design.","title":"Why was tailoring needed?"},{"location":"examples/example_1/#baseline-algorithm","text":"Upper level: stochastic local search; lower level: constructive heuristic. Motivations for choice: we wanted to keep it simple as possible and explainable for the user. No need to use fancy algorithms if a simple approach can obtain results.","title":"Baseline algorithm"},{"location":"examples/example_1/#tailoring-process","text":"Adding in constraints (part of the operators); added additional vehicle/machine swap operation; semi-guided mutation.","title":"Tailoring process"},{"location":"examples/example_1/#what-was-tailored","text":"Aspects of the algorithmic operators were tailored. This included the nature of the mutation operator and how it ensured that mutated solutions are feasible within the specific constraints of the problem.","title":"What was tailored"},{"location":"examples/example_1/#main-problem-characteristics","text":"Choose most important ones: low-dimensional at upper level, high-dimensional at lower level; highly constrained (some soft and some hard); offline; there is an existing solution that works(current fleet); is a simplified version of what is eventually sought (optimising routes, carbon as well); low data sensitivity.","title":"Main problem characteristics"},{"location":"examples/example_1/#references","text":"No response","title":"References"},{"location":"examples/example_1/#author","text":"Sarah Thomson","title":"Author"},{"location":"examples/example_2/","text":"Building spatial design \u00b6 Problem Description \u00b6 Optimise the spatial layout of a building to Minimise energy consumption for climate control, and Minimise the strain on the structure Why was tailoring needed? \u00b6 Many infeasible solutions exist. No algorithm existed/was found that could handle both multiple objectives, and a mixed-variable search space. Baseline algorithm \u00b6 SMS-EMOA. This performed best after initial tailoring steps needed to be able to run an algorithm at all, that were applied to both SMS-EMOA and NSGA-II. Tailoring process \u00b6 Design a superstructure problem representation to ensure the number of variables stays fixed (the existing representation would change the number of variables regularly). This made it possible to use standard EA frameworks . Modify algorithms designed for a single variable type to handle two variable types. ( Add existing standard mutation + crossover operators to handle variable types the algorithm cannot handle natively.) This made it possible to run an algorithm at all. Add equal penalty value for any solution that is infeasible . This led to only a very small number of feasible solutions, and not much optimisation yet. Penalty value based on the number of constraint violations (larger penalty for more violations). This led to more feasible solutions, and actually being able to optimise something. Design a problem-specific initialisation operator to ensure all initial solutions are feasible. This, combined with the next three steps, led to much better Pareto front approximations. Design a problem-specific mutation operator for the binary variables to ensure (standard operator was used for continuous variables, since there were no constraints on those) Remove the standard crossover operator , because it would cause many constraint violations (a new problem-specific crossover operator might be designed later, but proved to be very difficult to do) Add repair function was used to proportionally scale the continuous variables after mutation to match an equality constraint on them. Tune algorithm parameters to further improve performance. This led to further Pareto front approximation improvements. Add a local search step to try to improve solutions further by fixing the binary variables and optimising the continuous variables within that subspace.. This did not make much of a difference in the quality of the Pareto front approximation. Partial success : Although the developed approach worked in principle, it was quite limited in the size of the designs it could handle. For larger designs more modifications would be needed to ensure the problem-specific operators would not get stuck in a (fairly) local region of the search space. This was because the probability of finding a feasible mutation decreased when more modifications were made to the parent. (For small enough designs, the whole space would be local enough for things to work.) What was tailored \u00b6 No response Main problem characteristics \u00b6 Many hard constraints (simulator cannot evaluate the solution if these are violated) / Large part of the search space was infeasible. Checking if / how many constraints are violated is cheap. Mixed-variable search space (continuous + binary) Multiple objectives (Somewhat) expensive solution evaluations; with larger designs being more expensive. E.g., rough 1 second per evaluation for the smallest considered design, and roughly 40 seconds for the larger designs we considered. (Even the larger designs we considered are still relatively small for the considered problem.) Because of the above, we restricted ourselves to 2500 evaluations, but this was not a strict requirement. References \u00b6 No response Author \u00b6 Koen van der Blom","title":"Building spatial design"},{"location":"examples/example_2/#building-spatial-design","text":"","title":"Building spatial design"},{"location":"examples/example_2/#problem-description","text":"Optimise the spatial layout of a building to Minimise energy consumption for climate control, and Minimise the strain on the structure","title":"Problem Description"},{"location":"examples/example_2/#why-was-tailoring-needed","text":"Many infeasible solutions exist. No algorithm existed/was found that could handle both multiple objectives, and a mixed-variable search space.","title":"Why was tailoring needed?"},{"location":"examples/example_2/#baseline-algorithm","text":"SMS-EMOA. This performed best after initial tailoring steps needed to be able to run an algorithm at all, that were applied to both SMS-EMOA and NSGA-II.","title":"Baseline algorithm"},{"location":"examples/example_2/#tailoring-process","text":"Design a superstructure problem representation to ensure the number of variables stays fixed (the existing representation would change the number of variables regularly). This made it possible to use standard EA frameworks . Modify algorithms designed for a single variable type to handle two variable types. ( Add existing standard mutation + crossover operators to handle variable types the algorithm cannot handle natively.) This made it possible to run an algorithm at all. Add equal penalty value for any solution that is infeasible . This led to only a very small number of feasible solutions, and not much optimisation yet. Penalty value based on the number of constraint violations (larger penalty for more violations). This led to more feasible solutions, and actually being able to optimise something. Design a problem-specific initialisation operator to ensure all initial solutions are feasible. This, combined with the next three steps, led to much better Pareto front approximations. Design a problem-specific mutation operator for the binary variables to ensure (standard operator was used for continuous variables, since there were no constraints on those) Remove the standard crossover operator , because it would cause many constraint violations (a new problem-specific crossover operator might be designed later, but proved to be very difficult to do) Add repair function was used to proportionally scale the continuous variables after mutation to match an equality constraint on them. Tune algorithm parameters to further improve performance. This led to further Pareto front approximation improvements. Add a local search step to try to improve solutions further by fixing the binary variables and optimising the continuous variables within that subspace.. This did not make much of a difference in the quality of the Pareto front approximation. Partial success : Although the developed approach worked in principle, it was quite limited in the size of the designs it could handle. For larger designs more modifications would be needed to ensure the problem-specific operators would not get stuck in a (fairly) local region of the search space. This was because the probability of finding a feasible mutation decreased when more modifications were made to the parent. (For small enough designs, the whole space would be local enough for things to work.)","title":"Tailoring process"},{"location":"examples/example_2/#what-was-tailored","text":"No response","title":"What was tailored"},{"location":"examples/example_2/#main-problem-characteristics","text":"Many hard constraints (simulator cannot evaluate the solution if these are violated) / Large part of the search space was infeasible. Checking if / how many constraints are violated is cheap. Mixed-variable search space (continuous + binary) Multiple objectives (Somewhat) expensive solution evaluations; with larger designs being more expensive. E.g., rough 1 second per evaluation for the smallest considered design, and roughly 40 seconds for the larger designs we considered. (Even the larger designs we considered are still relatively small for the considered problem.) Because of the above, we restricted ourselves to 2500 evaluations, but this was not a strict requirement.","title":"Main problem characteristics"},{"location":"examples/example_2/#references","text":"No response","title":"References"},{"location":"examples/example_2/#author","text":"Koen van der Blom","title":"Author"},{"location":"examples/example_3/","text":"Combined Topology and Fibre-Orientation via Moving Morphable Components and Lamination Parameters \u00b6 Problem Description \u00b6 The idea is to optimize the topology or layout of a structure and the internal material layout. The topology was modelled via Moving Morphable Components (MMCs) wherein prescribed shapes are used to deform and move throughout a design 2D space. On the other hand, the fiber orientation was optimized by using the Lamination Parameter Formulation, which requires setting two parameters with global effects at some master nodes and the local fiber orientations are found by interpolation of these two parameters with respect to proximality to the master nodes. Why was tailoring needed? \u00b6 Normally, Topology Optimization requires more than 1000 design variables in most used formulations for this matter. Therefore, the Moving Morphable Components formulation was used to reduce dimensionality in a way that is tractable for black-box optimizers, but paying the cost of a much more reduced solution space. Simulation malfunctions required to be included as \u201cobjective constraints\u201d since some design combinations are numerically infeasible in the way the structure became kinematic and the underlying boundary conditions of the Finite Element solver weren\u2019t fulfilled. By evaluating the target for those sections of the search space, the algorithms get stuck since the target values are uninformative. For surrogate assisted optimization this is a big problem due to spurious correlations and discontinuities. Baseline algorithm \u00b6 No response Tailoring process \u00b6 Changed the target into a piecewise definition by evaluating first if the underlying structure complied with the boundary conditions. In other words, at least there was material connecting the structure from the support and there was material next to the load application. We adapted the function to handle constraints in an Augmented Lagrangian Fashion. We observed not so many works in the intersection of small feasible regions of search spaces and high-dimensional settings. However this may be counterproductive for Bayesian Optimization due to the discontinuity of the intersection of the feasible and unfeasible regions. What was tailored \u00b6 No response Main problem characteristics \u00b6 Continuous formulation of an inherent combinatorial high-dimensional space. Small feasible region or highly constrained Not all the search space can be evaluated and are meaningful. References \u00b6 No response Author \u00b6 Iv\u00e1n Olarte Rodr\u00edguez, Gokhan Serhat, Mariusz Bujny, Thomas Baeck, Elena Raponi","title":"Combined Topology and Fibre-Orientation via Moving Morphable Components and Lamination Parameters"},{"location":"examples/example_3/#combined-topology-and-fibre-orientation-via-moving-morphable-components-and-lamination-parameters","text":"","title":"Combined Topology and Fibre-Orientation via Moving Morphable Components and Lamination Parameters"},{"location":"examples/example_3/#problem-description","text":"The idea is to optimize the topology or layout of a structure and the internal material layout. The topology was modelled via Moving Morphable Components (MMCs) wherein prescribed shapes are used to deform and move throughout a design 2D space. On the other hand, the fiber orientation was optimized by using the Lamination Parameter Formulation, which requires setting two parameters with global effects at some master nodes and the local fiber orientations are found by interpolation of these two parameters with respect to proximality to the master nodes.","title":"Problem Description"},{"location":"examples/example_3/#why-was-tailoring-needed","text":"Normally, Topology Optimization requires more than 1000 design variables in most used formulations for this matter. Therefore, the Moving Morphable Components formulation was used to reduce dimensionality in a way that is tractable for black-box optimizers, but paying the cost of a much more reduced solution space. Simulation malfunctions required to be included as \u201cobjective constraints\u201d since some design combinations are numerically infeasible in the way the structure became kinematic and the underlying boundary conditions of the Finite Element solver weren\u2019t fulfilled. By evaluating the target for those sections of the search space, the algorithms get stuck since the target values are uninformative. For surrogate assisted optimization this is a big problem due to spurious correlations and discontinuities.","title":"Why was tailoring needed?"},{"location":"examples/example_3/#baseline-algorithm","text":"No response","title":"Baseline algorithm"},{"location":"examples/example_3/#tailoring-process","text":"Changed the target into a piecewise definition by evaluating first if the underlying structure complied with the boundary conditions. In other words, at least there was material connecting the structure from the support and there was material next to the load application. We adapted the function to handle constraints in an Augmented Lagrangian Fashion. We observed not so many works in the intersection of small feasible regions of search spaces and high-dimensional settings. However this may be counterproductive for Bayesian Optimization due to the discontinuity of the intersection of the feasible and unfeasible regions.","title":"Tailoring process"},{"location":"examples/example_3/#what-was-tailored","text":"No response","title":"What was tailored"},{"location":"examples/example_3/#main-problem-characteristics","text":"Continuous formulation of an inherent combinatorial high-dimensional space. Small feasible region or highly constrained Not all the search space can be evaluated and are meaningful.","title":"Main problem characteristics"},{"location":"examples/example_3/#references","text":"No response","title":"References"},{"location":"examples/example_3/#author","text":"Iv\u00e1n Olarte Rodr\u00edguez, Gokhan Serhat, Mariusz Bujny, Thomas Baeck, Elena Raponi","title":"Author"},{"location":"examples/example_4/","text":"Antenna control \u00b6 Problem Description \u00b6 tune a phased array antenna to steer it towards a target satellite, for telecommunication Why was tailoring needed? \u00b6 existing algorithms were either too inefficient, or required too many function evaluations Baseline algorithm \u00b6 surrogate-based optimization. To reduce the required number of function evaluations. Tailoring process \u00b6 The goal was to develop an algorithm that is efficient in the number of required function evaluations, but also in the computation time needed to propose a new candidate solution. The chosen framework was the same as in surrogate-based optimization: start with a candidate solution, evaluate the solution, update a surrogate model on the data gathered so far, then use the surrogate model to guide the search towards the optimal solution. The idea was that this framework would need less function evaluations than other black-box optimization algorithms such as evolutionary algorithms, though this was not tested. The chosen surrogate model was a Random Fourier Expansion, as it is efficient to train and to update, does not slow down over time like Gaussian processes, and has theoretical guarantees available. The chosen acquisition function was a type of epsilon-greedy exploration with local perturbations. This allowed for a fast convergence towards a local optimum, while not getting stuck at a local optimum. It avoided the need of spending computation time on calculating covariances or optimizing surrogate model hyperparameters. Hyperparameters of the approach were chosen based on expertise and initial experiments. For example, the number of basis functions was a hyperparameter that needed to be chosen such that it balances computational efficiency and performance. What was not successful: Nelder-Mead simplex method Powell\u2019s method using a quadratic surrogate model same as proposed approach but pure greedy (epsilon=0) \u2192 got stuck in local optima Bayesian optimization with Gaussian processes a more white-box approach that tried to linearize the problem Result good enough solution found within 2 minutes, with 3000 function evaluations solution 3000 times faster than Bayesian optimization with Gaussian processes solution twice as good as a predict-then-optimize approach with the same surrogate model What was tailored \u00b6 an algorithm was developed from scratch, with the same framework as other surrogate-based optimization algorithms. Main problem characteristics \u00b6 24 continuous variables with lower and upper bounds defined and no other constraints relatively cheap but noisy objective black-box, single-objective, single-fidelity, no parallelization Time constraint of 2 minutes (8 years ago, maybe now it would be 1 second or something) Function evaluation constraint of 3000 tested on a simulator, with the goal of eventually being applied on a physical system References \u00b6 optimal beam-forming network tuning more information on the application (not the algorithm) Contact information (optional) \u00b6 No response Author \u00b6 Laurens Bliek No response","title":"Antenna control"},{"location":"examples/example_4/#antenna-control","text":"","title":"Antenna control"},{"location":"examples/example_4/#problem-description","text":"tune a phased array antenna to steer it towards a target satellite, for telecommunication","title":"Problem Description"},{"location":"examples/example_4/#why-was-tailoring-needed","text":"existing algorithms were either too inefficient, or required too many function evaluations","title":"Why was tailoring needed?"},{"location":"examples/example_4/#baseline-algorithm","text":"surrogate-based optimization. To reduce the required number of function evaluations.","title":"Baseline algorithm"},{"location":"examples/example_4/#tailoring-process","text":"The goal was to develop an algorithm that is efficient in the number of required function evaluations, but also in the computation time needed to propose a new candidate solution. The chosen framework was the same as in surrogate-based optimization: start with a candidate solution, evaluate the solution, update a surrogate model on the data gathered so far, then use the surrogate model to guide the search towards the optimal solution. The idea was that this framework would need less function evaluations than other black-box optimization algorithms such as evolutionary algorithms, though this was not tested. The chosen surrogate model was a Random Fourier Expansion, as it is efficient to train and to update, does not slow down over time like Gaussian processes, and has theoretical guarantees available. The chosen acquisition function was a type of epsilon-greedy exploration with local perturbations. This allowed for a fast convergence towards a local optimum, while not getting stuck at a local optimum. It avoided the need of spending computation time on calculating covariances or optimizing surrogate model hyperparameters. Hyperparameters of the approach were chosen based on expertise and initial experiments. For example, the number of basis functions was a hyperparameter that needed to be chosen such that it balances computational efficiency and performance. What was not successful: Nelder-Mead simplex method Powell\u2019s method using a quadratic surrogate model same as proposed approach but pure greedy (epsilon=0) \u2192 got stuck in local optima Bayesian optimization with Gaussian processes a more white-box approach that tried to linearize the problem Result good enough solution found within 2 minutes, with 3000 function evaluations solution 3000 times faster than Bayesian optimization with Gaussian processes solution twice as good as a predict-then-optimize approach with the same surrogate model","title":"Tailoring process"},{"location":"examples/example_4/#what-was-tailored","text":"an algorithm was developed from scratch, with the same framework as other surrogate-based optimization algorithms.","title":"What was tailored"},{"location":"examples/example_4/#main-problem-characteristics","text":"24 continuous variables with lower and upper bounds defined and no other constraints relatively cheap but noisy objective black-box, single-objective, single-fidelity, no parallelization Time constraint of 2 minutes (8 years ago, maybe now it would be 1 second or something) Function evaluation constraint of 3000 tested on a simulator, with the goal of eventually being applied on a physical system","title":"Main problem characteristics"},{"location":"examples/example_4/#references","text":"optimal beam-forming network tuning more information on the application (not the algorithm)","title":"References"},{"location":"examples/example_4/#contact-information-optional","text":"No response","title":"Contact information (optional)"},{"location":"examples/example_4/#author","text":"Laurens Bliek No response","title":"Author"},{"location":"examples/example_5/","text":"Deep RL in Ludii (general game playing) \u00b6 Problem Description \u00b6 learning to play board games ( policies and/or value functions ) in the Ludii system: a single system with ~ 1400 distinct games described in its custom game description language (a DSL). Ludii compiles game description files into runnable simulators. Why was tailoring needed? \u00b6 biquitous assumption in pretty much the entire Deep RL field is that, when we have a domain (e.g., a particular game), we can precisely enumerate or define the whole action space. This is necessary for the established approach (which the entire field follows) for discrete-action-space tasks, where the number of output nodes of a neural network is equal to the number of actions. This is impossible in Ludii: from a game description file, I cannot automatically infer the action space of the entire game a priori. I can only, given a current state, generate a list of legal moves for that particular state . Hence: don\u2019t even know how many output nodes my neural network needs . Baseline algorithm \u00b6 AlphaZero-like training of a neural network with policy and state value heads, combined with MCTS. Tailoring process \u00b6 we could make a reasonable approximation of the action space that works okay for many games. But there are new risks that were never considered as possibilities by established deep RL methodologies: we sometimes have multiple different actions mapping to a single output node in the policy head. This raises questions about how to train that node (if one action is really good but the other really bad, should the output node have a high or low probability? Probably naively going in between is not great). There is also interesting interaction with the MCTS component, because it searches for a specific state at a time, and actually is able to distinguish between the actions that a DNN cannot distinguish between. Alternative solution is to include an actual feature-based representation of actions, and swap the action over to the input instead of the output. But then we need one forwards pass per action per state, instead of just one per state (giving outputs for all actions in parallel). Only explored this with linear functions, not DNNs. What was tailored \u00b6 problem description was tailored in the sense that we really want to use Ludii (no other system exists with anywhere close to as many different games). Given that constraint, tailoring of neural network architecture, training algorithm, and integration with search became necessary. Main problem characteristics \u00b6 Sequential decision-making. Discrete action space. Lots of problem instances (~1400 distinct board games) described in a single DSL. Somewhat inefficient simulator (due to need to compile from DSL). No automated inferencing (DSL is not logic-based). References \u00b6 No response Contact information (optional) \u00b6 No response Author \u00b6 Dennis Soemers No response","title":"Deep RL in Ludii (general game playing)"},{"location":"examples/example_5/#deep-rl-in-ludii-general-game-playing","text":"","title":"Deep RL in Ludii (general game playing)"},{"location":"examples/example_5/#problem-description","text":"learning to play board games ( policies and/or value functions ) in the Ludii system: a single system with ~ 1400 distinct games described in its custom game description language (a DSL). Ludii compiles game description files into runnable simulators.","title":"Problem Description"},{"location":"examples/example_5/#why-was-tailoring-needed","text":"biquitous assumption in pretty much the entire Deep RL field is that, when we have a domain (e.g., a particular game), we can precisely enumerate or define the whole action space. This is necessary for the established approach (which the entire field follows) for discrete-action-space tasks, where the number of output nodes of a neural network is equal to the number of actions. This is impossible in Ludii: from a game description file, I cannot automatically infer the action space of the entire game a priori. I can only, given a current state, generate a list of legal moves for that particular state . Hence: don\u2019t even know how many output nodes my neural network needs .","title":"Why was tailoring needed?"},{"location":"examples/example_5/#baseline-algorithm","text":"AlphaZero-like training of a neural network with policy and state value heads, combined with MCTS.","title":"Baseline algorithm"},{"location":"examples/example_5/#tailoring-process","text":"we could make a reasonable approximation of the action space that works okay for many games. But there are new risks that were never considered as possibilities by established deep RL methodologies: we sometimes have multiple different actions mapping to a single output node in the policy head. This raises questions about how to train that node (if one action is really good but the other really bad, should the output node have a high or low probability? Probably naively going in between is not great). There is also interesting interaction with the MCTS component, because it searches for a specific state at a time, and actually is able to distinguish between the actions that a DNN cannot distinguish between. Alternative solution is to include an actual feature-based representation of actions, and swap the action over to the input instead of the output. But then we need one forwards pass per action per state, instead of just one per state (giving outputs for all actions in parallel). Only explored this with linear functions, not DNNs.","title":"Tailoring process"},{"location":"examples/example_5/#what-was-tailored","text":"problem description was tailored in the sense that we really want to use Ludii (no other system exists with anywhere close to as many different games). Given that constraint, tailoring of neural network architecture, training algorithm, and integration with search became necessary.","title":"What was tailored"},{"location":"examples/example_5/#main-problem-characteristics","text":"Sequential decision-making. Discrete action space. Lots of problem instances (~1400 distinct board games) described in a single DSL. Somewhat inefficient simulator (due to need to compile from DSL). No automated inferencing (DSL is not logic-based).","title":"Main problem characteristics"},{"location":"examples/example_5/#references","text":"No response","title":"References"},{"location":"examples/example_5/#contact-information-optional","text":"No response","title":"Contact information (optional)"},{"location":"examples/example_5/#author","text":"Dennis Soemers No response","title":"Author"},{"location":"examples/example_6/","text":"MarioGAN \u00b6 Problem Description \u00b6 Generate (snippets of) Super Mario levels. Why was tailoring needed? \u00b6 Existing approaches usually use an encoding of the search space that maps tiles in the level directly to an entry in a matrix. This space then contains lots of unrealistic and unplayable levels, so it is unnecessarily big. We instead created a latent spaces that ideally only contains sensible levels and is easily searchable. Baseline algorithm \u00b6 Algorithm was not tailored, just the encoding. Since it was then turned into a single-objective continuous problem, we use cma-es (state-of-the-art) Tailoring process \u00b6 Colleagues had done latent variable search on another application, so we wanted to try it out here. There were some modifications later that changed the encoding further to prevent the creation of invalid levels (broken pipes). Lots of different objectives were also tried (since there is no clear given objective, it is a benchmarking problem) What was tailored \u00b6 No response Main problem characteristics \u00b6 Instances exist, search space is scalable Simulation-based evaluation with big spikes (adding one more tile to a pipe might make it unplayable) and large plateaus Not terribly expensive, but also not cheap Non-normal noise distribution (simulation of playthroughs is non-deterministic, and Mario tends to get stuck at specific points) References \u00b6 https://arxiv.org/abs/1805.00728 https://github.com/CIGbalance/DagstuhlGAN https://www.sciencedirect.com/science/article/pii/S1568494623001394 Contact information (optional) \u00b6 No response Author \u00b6 Vanessa Volz No response","title":"MarioGAN"},{"location":"examples/example_6/#mariogan","text":"","title":"MarioGAN"},{"location":"examples/example_6/#problem-description","text":"Generate (snippets of) Super Mario levels.","title":"Problem Description"},{"location":"examples/example_6/#why-was-tailoring-needed","text":"Existing approaches usually use an encoding of the search space that maps tiles in the level directly to an entry in a matrix. This space then contains lots of unrealistic and unplayable levels, so it is unnecessarily big. We instead created a latent spaces that ideally only contains sensible levels and is easily searchable.","title":"Why was tailoring needed?"},{"location":"examples/example_6/#baseline-algorithm","text":"Algorithm was not tailored, just the encoding. Since it was then turned into a single-objective continuous problem, we use cma-es (state-of-the-art)","title":"Baseline algorithm"},{"location":"examples/example_6/#tailoring-process","text":"Colleagues had done latent variable search on another application, so we wanted to try it out here. There were some modifications later that changed the encoding further to prevent the creation of invalid levels (broken pipes). Lots of different objectives were also tried (since there is no clear given objective, it is a benchmarking problem)","title":"Tailoring process"},{"location":"examples/example_6/#what-was-tailored","text":"No response","title":"What was tailored"},{"location":"examples/example_6/#main-problem-characteristics","text":"Instances exist, search space is scalable Simulation-based evaluation with big spikes (adding one more tile to a pipe might make it unplayable) and large plateaus Not terribly expensive, but also not cheap Non-normal noise distribution (simulation of playthroughs is non-deterministic, and Mario tends to get stuck at specific points)","title":"Main problem characteristics"},{"location":"examples/example_6/#references","text":"https://arxiv.org/abs/1805.00728 https://github.com/CIGbalance/DagstuhlGAN https://www.sciencedirect.com/science/article/pii/S1568494623001394","title":"References"},{"location":"examples/example_6/#contact-information-optional","text":"No response","title":"Contact information (optional)"},{"location":"examples/example_6/#author","text":"Vanessa Volz No response","title":"Author"}]}